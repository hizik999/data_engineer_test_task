Здравствуйте! Я Малышев Андрей, вот мое решение тестового задания на Junior Data Engineer
[Задание](<Тестовое задание Data Engineer.pdf>)
## Что в репозитории
- папка data (там содержится tobacco_company_data.xlsx файл, тот, что по ссылке из задания)
- outputs (там будут лежать полученные в результате выполнения SQL запросов из SQL части задания файлы с расширением .csv)
- .gitignore (игнор для гита)
- файл с заданием "Тестовое задание Data Engineer.pdf"
- database.py (файл с конфигурацией базы данных и методом для создания таблиц)
- main.py (основной файл, который надо запустить и где выполняются все задания)
- models.py (файл с моделями данных из условия)
- README.md (этот файл)
- requirements.txt (файл с зависимостями, которые надо установить, чтобы код работал)
- sql_queries.py (файл с SQL скриптами из SQL части задания)

## Инструкция по установке зависимостей и запуске кода
0. Скачайте архив и распакуйте его, зайдя в папку, или выполните
```
git clone https://github.com/hizik999/data_engineer_test_task.git
```
1. Создайте и активируйте виртуальное окружение и активируйте его (у меня MacOS, поэтому пишу вот так, на других ОС по-другому)
```
python3 -m venv venv
source venv/bin/activate
```
должно появиться (venv) в начале строки терминала
2. Установите зависимости из файла requirements.txt
```
pip install -r requirements.txt
```
3. Откройте main.py и запустите его
должно вывести следующее:
```
Таблицы созданы
Данные получены
Данные загружены
Запросы выполнены
Результаты записаны
Транзакции предобработаны
Рассчет процентого роста продаж...
   month  growth_rate
0      1          NaN
1      3        -27.3
2      4        -85.0
3      6        733.3
Процентный рост по месяцам посчитан
Задания выполнены
```

### Ответы на вопросы по Airflow
1. DAG - directed asyclic graph - структура для управления последовательностью задач, представляет собой направленный ациклический граф. В его контексте задачи выполняются в заданном порядке, есть возможность передавать данные из одной задачи в другую и видеть состояния и логи.
2. Три главных компонента архитектуры Airflow:
    1. Scheduler - веб-сервер, который управляет запуском DAG'ов
    2. Executor - исполняет DAG'и (основные - SequentialExecutor, LocalExecutor, CeleryExecutor)
    3. Metadata Database - база данных, где хранится вся информация об Airflow (DAG, юзеры, статусы задач и т.д.)
3. Нет, в веб версии менять код DAG'a нельзя, но если изменить его в файле на локальной машине и обновить страницу, то код обновится и будет актуальным